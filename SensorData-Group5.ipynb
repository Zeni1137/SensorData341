{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe5b272",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue; text-align:center\"> ISAT341- Machine Learning and Data Science </h1>\n",
    "\n",
    "<h2 style=\"color:Green; text-align:center; font-family:ComicSans\"> Project: Machine Learning Confidential Sensor Data </h2>\n",
    "\n",
    "<img src=\"images/machine_learning.jpg\" width=200; height=200>\n",
    "\n",
    "\n",
    "<h2 style=\"color:Green; text-align:center; font-family:ComicSans\"> Working with real-world datasets</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9056cd84",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "To demonstrate the ability to complete an end-to-end data science / machine learning project using real-world data by following and implementing the main machine learning checklist steps that lead to a solution, namely:\n",
    "\n",
    "* Frame the problem and look at the big picture.\n",
    "* Get the data.\n",
    "* Explore the data to gain insights.\n",
    "* Prepare the data to expose the underlying data patterns to Machine Learning algorithms.\n",
    "* Explore many different models and short-list the best ones.\n",
    "* Fine-tune your models and combine them into a great solution.\n",
    "* Present your solution.\n",
    "* Launch, monitor, and maintain your system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eae62b7",
   "metadata": {},
   "source": [
    "## Frame the Problem\n",
    "\n",
    "<img src=\"images/sensor_array.jpg\" width=300; height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e0142d",
   "metadata": {},
   "source": [
    "### Sensor Data\n",
    "\n",
    "The data source as well as the exact nature of the data is confidential. Each data instance contains 12 real-valued input attributes. Each input\n",
    "attribute represents a sensor designed to detect the presence of one of two groups of substances. As an alternative, the sensor readings may\n",
    "represent a 'false alarm'.\n",
    "\n",
    "* Substance 1 is represented by the value 'one' in the class attribute column.\n",
    "* Substance 2 is represented by the value 'two' in the class attribute column.\n",
    "* A false alarm is represented by the value 'three' in the class attribute column.\n",
    "\n",
    "The problem is framed as a **supervised learning** problem: Predict the class of a substance from sensor data using the given measurements in\n",
    "the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d35b9b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2560900",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e70ef3e",
   "metadata": {},
   "source": [
    "### TO DO: Use Pandas to load your data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3a76b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.473</td>\n",
       "      <td>2.311</td>\n",
       "      <td>3.179</td>\n",
       "      <td>2.666</td>\n",
       "      <td>0.2795</td>\n",
       "      <td>0.2771</td>\n",
       "      <td>0.22340</td>\n",
       "      <td>0.1855</td>\n",
       "      <td>0.2539</td>\n",
       "      <td>1.138</td>\n",
       "      <td>1.111</td>\n",
       "      <td>4.712</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.460</td>\n",
       "      <td>2.377</td>\n",
       "      <td>3.214</td>\n",
       "      <td>2.920</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>0.3064</td>\n",
       "      <td>0.02563</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.3027</td>\n",
       "      <td>1.213</td>\n",
       "      <td>1.027</td>\n",
       "      <td>5.463</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.552</td>\n",
       "      <td>2.164</td>\n",
       "      <td>3.064</td>\n",
       "      <td>2.745</td>\n",
       "      <td>0.2820</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.17210</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>1.221</td>\n",
       "      <td>1.058</td>\n",
       "      <td>5.332</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.605</td>\n",
       "      <td>2.228</td>\n",
       "      <td>3.149</td>\n",
       "      <td>2.834</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.2734</td>\n",
       "      <td>1.144</td>\n",
       "      <td>1.062</td>\n",
       "      <td>4.829</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.534</td>\n",
       "      <td>2.114</td>\n",
       "      <td>3.309</td>\n",
       "      <td>2.976</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.2502</td>\n",
       "      <td>0.22580</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>1.254</td>\n",
       "      <td>1.112</td>\n",
       "      <td>5.734</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input 1  Input 2  Input 3  Input 4  Input 5  Input 6  Input 7  Input 8  \\\n",
       "0    1.473    2.311    3.179    2.666   0.2795   0.2771  0.22340   0.1855   \n",
       "1    1.460    2.377    3.214    2.920   0.2527   0.3064  0.02563   0.1965   \n",
       "2    1.552    2.164    3.064    2.745   0.2820   0.2100  0.17210   0.1929   \n",
       "3    1.605    2.228    3.149    2.834   0.2917   0.3613  0.20870   0.1294   \n",
       "4    1.534    2.114    3.309    2.976   0.2100   0.2502  0.22580   0.1770   \n",
       "\n",
       "   Input 9  Input 10  Input 11  Input 12 class  \n",
       "0   0.2539     1.138     1.111     4.712   one  \n",
       "1   0.3027     1.213     1.027     5.463   one  \n",
       "2   0.2100     1.221     1.058     5.332   one  \n",
       "3   0.2734     1.144     1.062     4.829   one  \n",
       "4   0.2039     1.254     1.112     5.734   one  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first ten rows after you load the data.\n",
    "df = pd.read_csv(\"data/Sensor_Data_Confidential_341Project_DataSet5.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30fa305",
   "metadata": {},
   "source": [
    "### TO DO: Use the dataframe describe method dataframe.describe() to display some summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68eaafde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-102.944836</td>\n",
       "      <td>-109.711795</td>\n",
       "      <td>-111.319884</td>\n",
       "      <td>-67.994856</td>\n",
       "      <td>-124.949039</td>\n",
       "      <td>-105.066162</td>\n",
       "      <td>-81.658039</td>\n",
       "      <td>-125.587986</td>\n",
       "      <td>-100.835192</td>\n",
       "      <td>-74.740051</td>\n",
       "      <td>-85.312925</td>\n",
       "      <td>-78.599944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1027.427211</td>\n",
       "      <td>1050.057089</td>\n",
       "      <td>1072.729741</td>\n",
       "      <td>849.911071</td>\n",
       "      <td>1115.540299</td>\n",
       "      <td>1027.206775</td>\n",
       "      <td>903.995215</td>\n",
       "      <td>1115.467928</td>\n",
       "      <td>1003.772889</td>\n",
       "      <td>877.403031</td>\n",
       "      <td>930.088695</td>\n",
       "      <td>904.281076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.058500</td>\n",
       "      <td>0.817600</td>\n",
       "      <td>4.848250</td>\n",
       "      <td>3.998250</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.649400</td>\n",
       "      <td>0.308800</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.423600</td>\n",
       "      <td>1.379000</td>\n",
       "      <td>1.089000</td>\n",
       "      <td>0.789800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.082000</td>\n",
       "      <td>1.353000</td>\n",
       "      <td>5.336000</td>\n",
       "      <td>5.041000</td>\n",
       "      <td>0.806300</td>\n",
       "      <td>1.634500</td>\n",
       "      <td>0.565200</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>0.694600</td>\n",
       "      <td>1.996000</td>\n",
       "      <td>1.285500</td>\n",
       "      <td>4.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.504000</td>\n",
       "      <td>2.354250</td>\n",
       "      <td>5.591250</td>\n",
       "      <td>5.642750</td>\n",
       "      <td>1.400750</td>\n",
       "      <td>2.159000</td>\n",
       "      <td>0.959800</td>\n",
       "      <td>0.491900</td>\n",
       "      <td>1.234250</td>\n",
       "      <td>4.974000</td>\n",
       "      <td>1.865250</td>\n",
       "      <td>5.403000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.105000</td>\n",
       "      <td>4.675000</td>\n",
       "      <td>5.944000</td>\n",
       "      <td>6.013000</td>\n",
       "      <td>2.754000</td>\n",
       "      <td>3.638000</td>\n",
       "      <td>2.446000</td>\n",
       "      <td>1.199000</td>\n",
       "      <td>2.561000</td>\n",
       "      <td>5.312000</td>\n",
       "      <td>5.640000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Input 1      Input 2      Input 3      Input 4      Input 5  \\\n",
       "count  2064.000000  2064.000000  2064.000000  2064.000000  2064.000000   \n",
       "mean   -102.944836  -109.711795  -111.319884   -67.994856  -124.949039   \n",
       "std    1027.427211  1050.057089  1072.729741   849.911071  1115.540299   \n",
       "min   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "25%       3.058500     0.817600     4.848250     3.998250     0.462600   \n",
       "50%       4.082000     1.353000     5.336000     5.041000     0.806300   \n",
       "75%       4.504000     2.354250     5.591250     5.642750     1.400750   \n",
       "max       5.105000     4.675000     5.944000     6.013000     2.754000   \n",
       "\n",
       "           Input 6      Input 7      Input 8      Input 9     Input 10  \\\n",
       "count  2064.000000  2064.000000  2064.000000  2064.000000  2064.000000   \n",
       "mean   -105.066162   -81.658039  -125.587986  -100.835192   -74.740051   \n",
       "std    1027.206775   903.995215  1115.467928  1003.772889   877.403031   \n",
       "min   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "25%       0.649400     0.308800     0.188000     0.423600     1.379000   \n",
       "50%       1.634500     0.565200     0.302700     0.694600     1.996000   \n",
       "75%       2.159000     0.959800     0.491900     1.234250     4.974000   \n",
       "max       3.638000     2.446000     1.199000     2.561000     5.312000   \n",
       "\n",
       "          Input 11     Input 12  \n",
       "count  2064.000000  2064.000000  \n",
       "mean    -85.312925   -78.599944  \n",
       "std     930.088695   904.281076  \n",
       "min   -9999.000000 -9999.000000  \n",
       "25%       1.089000     0.789800  \n",
       "50%       1.285500     4.915000  \n",
       "75%       1.865250     5.403000  \n",
       "max       5.640000    20.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293c14c9",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16d8c59",
   "metadata": {},
   "source": [
    "### TO DO: Display the shape of your dataframe data in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ac6ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2064, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b126f5d",
   "metadata": {},
   "source": [
    "### TO DO: Use Pandas dataframe to find bad or missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b9838fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.473</td>\n",
       "      <td>2.311</td>\n",
       "      <td>3.179</td>\n",
       "      <td>2.666</td>\n",
       "      <td>0.27950</td>\n",
       "      <td>0.27710</td>\n",
       "      <td>0.22340</td>\n",
       "      <td>0.18550</td>\n",
       "      <td>0.2539</td>\n",
       "      <td>1.138</td>\n",
       "      <td>1.1110</td>\n",
       "      <td>4.712</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.460</td>\n",
       "      <td>2.377</td>\n",
       "      <td>3.214</td>\n",
       "      <td>2.920</td>\n",
       "      <td>0.25270</td>\n",
       "      <td>0.30640</td>\n",
       "      <td>0.02563</td>\n",
       "      <td>0.19650</td>\n",
       "      <td>0.3027</td>\n",
       "      <td>1.213</td>\n",
       "      <td>1.0270</td>\n",
       "      <td>5.463</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.552</td>\n",
       "      <td>2.164</td>\n",
       "      <td>3.064</td>\n",
       "      <td>2.745</td>\n",
       "      <td>0.28200</td>\n",
       "      <td>0.21000</td>\n",
       "      <td>0.17210</td>\n",
       "      <td>0.19290</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>1.221</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>5.332</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.605</td>\n",
       "      <td>2.228</td>\n",
       "      <td>3.149</td>\n",
       "      <td>2.834</td>\n",
       "      <td>0.29170</td>\n",
       "      <td>0.36130</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.12940</td>\n",
       "      <td>0.2734</td>\n",
       "      <td>1.144</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>4.829</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.534</td>\n",
       "      <td>2.114</td>\n",
       "      <td>3.309</td>\n",
       "      <td>2.976</td>\n",
       "      <td>0.21000</td>\n",
       "      <td>0.25020</td>\n",
       "      <td>0.22580</td>\n",
       "      <td>0.17700</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>1.254</td>\n",
       "      <td>1.1120</td>\n",
       "      <td>5.734</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.566</td>\n",
       "      <td>2.323</td>\n",
       "      <td>3.469</td>\n",
       "      <td>2.711</td>\n",
       "      <td>0.24170</td>\n",
       "      <td>0.05371</td>\n",
       "      <td>0.21120</td>\n",
       "      <td>-0.02686</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>1.158</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>4.780</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.425</td>\n",
       "      <td>2.152</td>\n",
       "      <td>3.287</td>\n",
       "      <td>2.781</td>\n",
       "      <td>0.29910</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>0.10380</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>1.271</td>\n",
       "      <td>1.1150</td>\n",
       "      <td>5.662</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.595</td>\n",
       "      <td>2.271</td>\n",
       "      <td>3.323</td>\n",
       "      <td>2.743</td>\n",
       "      <td>0.17330</td>\n",
       "      <td>0.19650</td>\n",
       "      <td>0.16850</td>\n",
       "      <td>0.05859</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>1.290</td>\n",
       "      <td>1.0330</td>\n",
       "      <td>5.145</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.628</td>\n",
       "      <td>2.211</td>\n",
       "      <td>3.176</td>\n",
       "      <td>2.710</td>\n",
       "      <td>0.08423</td>\n",
       "      <td>0.18920</td>\n",
       "      <td>0.27830</td>\n",
       "      <td>0.16850</td>\n",
       "      <td>0.3491</td>\n",
       "      <td>1.155</td>\n",
       "      <td>1.0080</td>\n",
       "      <td>5.613</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.583</td>\n",
       "      <td>2.253</td>\n",
       "      <td>3.278</td>\n",
       "      <td>2.854</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22830</td>\n",
       "      <td>0.07324</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>1.135</td>\n",
       "      <td>1.1120</td>\n",
       "      <td>5.549</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Input 1  Input 2  Input 3  Input 4  Input 5  Input 6  Input 7  Input 8  \\\n",
       "0     1.473    2.311    3.179    2.666  0.27950  0.27710  0.22340  0.18550   \n",
       "1     1.460    2.377    3.214    2.920  0.25270  0.30640  0.02563  0.19650   \n",
       "2     1.552    2.164    3.064    2.745  0.28200  0.21000  0.17210  0.19290   \n",
       "3     1.605    2.228    3.149    2.834  0.29170  0.36130  0.20870  0.12940   \n",
       "4     1.534    2.114    3.309    2.976  0.21000  0.25020  0.22580  0.17700   \n",
       "6     1.566    2.323    3.469    2.711  0.24170  0.05371  0.21120 -0.02686   \n",
       "7     1.425    2.152    3.287    2.781  0.29910  0.20750  0.10380  0.11470   \n",
       "8     1.595    2.271    3.323    2.743  0.17330  0.19650  0.16850  0.05859   \n",
       "9     1.628    2.211    3.176    2.710  0.08423  0.18920  0.27830  0.16850   \n",
       "10    1.583    2.253    3.278    2.854  0.14890  0.10990  0.22830  0.07324   \n",
       "\n",
       "    Input 9  Input 10  Input 11  Input 12 class  \n",
       "0    0.2539     1.138    1.1110     4.712   one  \n",
       "1    0.3027     1.213    1.0270     5.463   one  \n",
       "2    0.2100     1.221    1.0580     5.332   one  \n",
       "3    0.2734     1.144    1.0620     4.829   one  \n",
       "4    0.2039     1.254    1.1120     5.734   one  \n",
       "6    0.2197     1.158    0.9924     4.780   one  \n",
       "7    0.2698     1.271    1.1150     5.662   one  \n",
       "8    0.2051     1.290    1.0330     5.145   one  \n",
       "9    0.3491     1.155    1.0080     5.613   one  \n",
       "10   0.2173     1.135    1.1120     5.549   one  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Enter your code in the cell below to implement the drop, replace and display.\n",
    "df = df.replace(-9999.0, np.nan)\n",
    "df = df.dropna()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f4ccc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1826, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of data in dataframe after cleansing\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e232cd9e",
   "metadata": {},
   "source": [
    "### TO DO: Use pandas correlation method to find the two features (inputs) with the highest correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e898ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Input 1   Input 2   Input 3   Input 4   Input 5   Input 6  \\\n",
      "Input 1   1.000000  0.527248  0.932390  0.938750  0.748763  0.900299   \n",
      "Input 2   0.527248  1.000000  0.463356  0.505046  0.416400  0.614186   \n",
      "Input 3   0.932390  0.463356  1.000000  0.884079  0.643788  0.813403   \n",
      "Input 4   0.938750  0.505046  0.884079  1.000000  0.812194  0.877337   \n",
      "Input 5   0.748763  0.416400  0.643788  0.812194  1.000000  0.834460   \n",
      "Input 6   0.900299  0.614186  0.813403  0.877337  0.834460  1.000000   \n",
      "Input 7   0.701600  0.426394  0.596152  0.734622  0.905794  0.772869   \n",
      "Input 8   0.675776  0.437816  0.574708  0.727402  0.901688  0.764765   \n",
      "Input 9   0.722770  0.435743  0.630974  0.802189  0.972590  0.825776   \n",
      "Input 10  0.692099  0.449897  0.605835  0.764233  0.885527  0.827059   \n",
      "Input 11  0.464854  0.352147  0.403812  0.537204  0.742445  0.657962   \n",
      "Input 12  0.160311  0.091390  0.160420  0.159417  0.183917  0.181238   \n",
      "\n",
      "           Input 7   Input 8   Input 9  Input 10  Input 11  Input 12  \n",
      "Input 1   0.701600  0.675776  0.722770  0.692099  0.464854  0.160311  \n",
      "Input 2   0.426394  0.437816  0.435743  0.449897  0.352147  0.091390  \n",
      "Input 3   0.596152  0.574708  0.630974  0.605835  0.403812  0.160420  \n",
      "Input 4   0.734622  0.727402  0.802189  0.764233  0.537204  0.159417  \n",
      "Input 5   0.905794  0.901688  0.972590  0.885527  0.742445  0.183917  \n",
      "Input 6   0.772869  0.764765  0.825776  0.827059  0.657962  0.181238  \n",
      "Input 7   1.000000  0.944429  0.845032  0.810357  0.536046  0.225150  \n",
      "Input 8   0.944429  1.000000  0.858171  0.815908  0.566306  0.234747  \n",
      "Input 9   0.845032  0.858171  1.000000  0.880231  0.805716  0.192808  \n",
      "Input 10  0.810357  0.815908  0.880231  1.000000  0.720474  0.168878  \n",
      "Input 11  0.536046  0.566306  0.805716  0.720474  1.000000  0.058959  \n",
      "Input 12  0.225150  0.234747  0.192808  0.168878  0.058959  1.000000  \n",
      "\n",
      "Inputs 9 and 5 are the most correlated with a correlation of 0.97259\n"
     ]
    }
   ],
   "source": [
    "#Enter your answers in the cell immediately following the output correlation table\n",
    "corrs = abs(df.corr(numeric_only=True))\n",
    "print(corrs)\n",
    "print()\n",
    "print(\"Inputs 9 and 5 are the most correlated with a correlation of 0.97259\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0b3ab3",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0248b59e",
   "metadata": {},
   "source": [
    "### TO DO: Plot bar charts using pandas dataframe (plot the mean value of the sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b235dc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean values are: \n",
      "Input 1     3.680058\n",
      "Input 2     1.727913\n",
      "Input 3     5.009482\n",
      "Input 4     4.709107\n",
      "Input 5     1.015576\n",
      "Input 6     1.525255\n",
      "Input 7     0.700818\n",
      "Input 8     0.372550\n",
      "Input 9     0.904062\n",
      "Input 10    2.779109\n",
      "Input 11    1.886693\n",
      "Input 12    3.772419\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = df.columns.tolist()\n",
    "\n",
    "features = len(columns)-1\n",
    "columns = columns[:features]\n",
    "\n",
    "print('The mean values are: \\n{}'.format(df.mean(numeric_only=True)))\n",
    "\n",
    "mean_values = df[:].mean(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(columns, mean_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e67e15",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ccfd8",
   "metadata": {},
   "source": [
    "### TO DO: Create Feature Matrix and Target Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4001327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Input 1  Input 2  Input 3  Input 4  Input 5  Input 6  Input 7  Input 8  \\\n",
      "0       1.473    2.311    3.179    2.666   0.2795   0.2771  0.22340  0.18550   \n",
      "1       1.460    2.377    3.214    2.920   0.2527   0.3064  0.02563  0.19650   \n",
      "2       1.552    2.164    3.064    2.745   0.2820   0.2100  0.17210  0.19290   \n",
      "3       1.605    2.228    3.149    2.834   0.2917   0.3613  0.20870  0.12940   \n",
      "4       1.534    2.114    3.309    2.976   0.2100   0.2502  0.22580  0.17700   \n",
      "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "2059    3.682    1.301    4.939    4.453   0.4895   0.7922  0.23190  0.05005   \n",
      "2060    3.412    1.293    4.949    4.199   0.4578   0.9521  0.21360  0.23070   \n",
      "2061    3.640    1.284    5.111    4.460   0.5786   0.8020  0.26980  0.31740   \n",
      "2062    3.746    1.261    5.049    4.885   0.5835   1.1470  0.32350  0.23070   \n",
      "2063    3.959    1.108    5.422    4.835   0.5579   1.3230  0.51510  0.21000   \n",
      "\n",
      "      Input 9  Input 10  Input 11  Input 12  \n",
      "0      0.2539     1.138     1.111     4.712  \n",
      "1      0.3027     1.213     1.027     5.463  \n",
      "2      0.2100     1.221     1.058     5.332  \n",
      "3      0.2734     1.144     1.062     4.829  \n",
      "4      0.2039     1.254     1.112     5.734  \n",
      "...       ...       ...       ...       ...  \n",
      "2059   0.3687     1.478     1.174     5.125  \n",
      "2060   0.4578     1.526     1.167     5.433  \n",
      "2061   0.4309     1.460     1.118     4.867  \n",
      "2062   0.4614     1.482     1.128     5.627  \n",
      "2063   0.5737     1.595     1.244     5.623  \n",
      "\n",
      "[1826 rows x 12 columns]\n",
      "0       one\n",
      "1       one\n",
      "2       one\n",
      "3       one\n",
      "4       one\n",
      "       ... \n",
      "2059    two\n",
      "2060    two\n",
      "2061    two\n",
      "2062    two\n",
      "2063    two\n",
      "Name: class, Length: 1826, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# \"Features\" are also known as predictors, inputs, or attributes. The \"response\" is also known as the target, label, or output.\n",
    "X  =df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b677ab",
   "metadata": {},
   "source": [
    "### TO DO: Convert the features dataframe to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d767dc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.473, 2.311, 3.179, ..., 1.138, 1.111, 4.712],\n",
       "       [1.46 , 2.377, 3.214, ..., 1.213, 1.027, 5.463],\n",
       "       [1.552, 2.164, 3.064, ..., 1.221, 1.058, 5.332],\n",
       "       ...,\n",
       "       [3.64 , 1.284, 5.111, ..., 1.46 , 1.118, 4.867],\n",
       "       [3.746, 1.261, 5.049, ..., 1.482, 1.128, 5.627],\n",
       "       [3.959, 1.108, 5.422, ..., 1.595, 1.244, 5.623]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcff8aff",
   "metadata": {},
   "source": [
    "### TO DO: Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d89545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The categorical classes are ['one' 'three' 'two']\n",
      "\n",
      "500 sample encoded values:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "encoded shape: (1826,)\n"
     ]
    }
   ],
   "source": [
    "# Transform the categorical labels into integers using the scikit-learn label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Instanciate integer encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#encode the class labels \n",
    "label_encoder.fit(y)\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "#print the categorical class labels we encoded (note the underscore!)\n",
    "print('The categorical classes are {}\\n'.format(label_encoder.classes_))\n",
    "\n",
    "#print a few encoded values using python slice\n",
    "print('500 sample encoded values:')\n",
    "print(y_encoded[slice(500)])\n",
    "\n",
    "#print the shape of the ecoded classes\n",
    "print('\\nencoded shape:', y_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca46d19d",
   "metadata": {},
   "source": [
    "### TO DO: Split the data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d1e674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Use a 80% / 20% train/test split for this project.\n",
    "#NOTE: You must use the encoded class labels in this part\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_encoded,test_size=.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b66560",
   "metadata": {},
   "source": [
    "### TO DO:Look at the shape of the data (rows and columns) after splitting it into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49df05b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train: (1460, 12)\n",
      "The shape of y_train: (1460,)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "print('The shape of X_train: {}'.format(X_train.shape))\n",
    "print('The shape of y_train: {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e7141ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_test: (366, 12)\n",
      "The shape of y_test: (366,)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print('The shape of X_test: {}'.format(X_test.shape))\n",
    "print('The shape of y_test: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61cce8c",
   "metadata": {},
   "source": [
    "## Scale The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9ac01",
   "metadata": {},
   "source": [
    "### TO DO: Let's use the StandarScaler from Scikit-learn to transform (scale) our feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caac9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the Features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "# from this point forward you must use the scaled training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2108c",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b468cd",
   "metadata": {},
   "source": [
    "Algorithms being used: \n",
    "1. K-Nearest Neighbor (with K=10, K=50, K=200)\n",
    "2. Logistic Regression\n",
    "3. Linear Support Vector Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72f9b88",
   "metadata": {},
   "source": [
    "## Build a KNN Classification Model for K = 10, 50 and 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bca5b9",
   "metadata": {},
   "source": [
    "### TO DO: In the sections below you should build and train the actual machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb2f28b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 200\n",
      "Test accuracy: 0.86\n",
      "\n",
      "KNN: 10\n",
      "Test accuracy: 0.98\n",
      "\n",
      "KNN: 50\n",
      "Test accuracy: 0.96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In the cell below: enter the code to import, instantiate, fit, \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "#predict and test the model's performance (accuracy) for the K-Nearest Neighbor Model in SciKit-Learn for K= 10, 50 and 200. \n",
    "#!!! This should be completed in ONE cell using a loop, etc. !!!!\n",
    "\n",
    "knn_loop = {10,50,200}\n",
    "\n",
    "for i in knn_loop:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train_std,y_train)\n",
    "    y_pred = knn.predict(X_test_std)\n",
    "    print('KNN: {}'.format(i))\n",
    "    print('Test accuracy: {0:0.2f}\\n'.format(knn.score(X_test_std,y_test)))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e17fd4",
   "metadata": {},
   "source": [
    "### Predicting class-membership probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61d1c4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict_proba(X_test_std[:3, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26700cf7",
   "metadata": {},
   "source": [
    "### TO DO:class-membership probability index = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f18e4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 200\n",
      "There is a 18.0% chance that X_test 10  belongs to class 0\n",
      "There is a 0.0% chance that X_test 10  belongs to class 1\n",
      "There is a 82.0% chance that X_test 10  belongs to class 2\n",
      "\n",
      "KNN: 10\n",
      "There is a 0.0% chance that X_test 10  belongs to class 0\n",
      "There is a 0.0% chance that X_test 10  belongs to class 1\n",
      "There is a 100.0% chance that X_test 10  belongs to class 2\n",
      "\n",
      "KNN: 50\n",
      "There is a 0.0% chance that X_test 10  belongs to class 0\n",
      "There is a 0.0% chance that X_test 10  belongs to class 1\n",
      "There is a 100.0% chance that X_test 10  belongs to class 2\n",
      "\n",
      "True Value: 2\n"
     ]
    }
   ],
   "source": [
    "#Predict the class membership probability by using the a row with index = 10 from the X_test_std data. \n",
    "\n",
    "#Make sure your print statement uses a complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test\n",
    "\n",
    "for i in knn_loop:\n",
    "    index = 10\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train_std,y_train)\n",
    "    print('KNN: {}'.format(i))\n",
    "    print('There is a {}% chance that X_test {}  belongs to class 0'.format(knn.predict_proba(X_test_std)[index][0]*100,index))\n",
    "    print('There is a {}% chance that X_test {}  belongs to class 1'.format(knn.predict_proba(X_test_std)[index][1]*100,index))\n",
    "    print('There is a {}% chance that X_test {}  belongs to class 2'.format(knn.predict_proba(X_test_std)[index][2]*100,index))\n",
    "    print()\n",
    "print('True Value: {}'.format(y_test[index]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5541c5b",
   "metadata": {},
   "source": [
    "### TO DO:class-membership probability index = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c74d7c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 200\n",
      "There is a 3.0% chance that X_test 125  belongs to class 0\n",
      "There is a 0.0% chance that X_test 125  belongs to class 1\n",
      "There is a 97.0% chance that X_test 125  belongs to class 2\n",
      "\n",
      "KNN: 10\n",
      "There is a 0.0% chance that X_test 125  belongs to class 0\n",
      "There is a 0.0% chance that X_test 125  belongs to class 1\n",
      "There is a 100.0% chance that X_test 125  belongs to class 2\n",
      "\n",
      "KNN: 50\n",
      "There is a 0.0% chance that X_test 125  belongs to class 0\n",
      "There is a 0.0% chance that X_test 125  belongs to class 1\n",
      "There is a 100.0% chance that X_test 125  belongs to class 2\n",
      "\n",
      "True Value: 2\n"
     ]
    }
   ],
   "source": [
    "# Same steps as above\n",
    "for i in knn_loop:\n",
    "    index = 125\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train_std,y_train)\n",
    "    print('KNN: {}'.format(i))\n",
    "    print('There is a {}% chance that X_test {}  belongs to class 0'.format(knn.predict_proba(X_test_std)[index][0]*100,index))\n",
    "    print('There is a {}% chance that X_test {}  belongs to class 1'.format(knn.predict_proba(X_test_std)[index][1]*100,index))\n",
    "    print('There is a {}% chance that X_test {}  belongs to class 2'.format(knn.predict_proba(X_test_std)[index][2]*100,index))\n",
    "    print()\n",
    "print('True Value: {}'.format(y_test[index]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f987a005",
   "metadata": {},
   "source": [
    "### TO DO:class-membership probability index = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3db779a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 200\n",
      "There is a 98.0% chance that X_test 200  belongs to class 0\n",
      "There is a 0.0% chance that X_test 200  belongs to class 1\n",
      "There is a 2.0% chance that X_test 200  belongs to class 2\n",
      "\n",
      "KNN: 10\n",
      "There is a 100.0% chance that X_test 200  belongs to class 0\n",
      "There is a 0.0% chance that X_test 200  belongs to class 1\n",
      "There is a 0.0% chance that X_test 200  belongs to class 2\n",
      "\n",
      "KNN: 50\n",
      "There is a 100.0% chance that X_test 200  belongs to class 0\n",
      "There is a 0.0% chance that X_test 200  belongs to class 1\n",
      "There is a 0.0% chance that X_test 200  belongs to class 2\n",
      "\n",
      "True Value: 0\n"
     ]
    }
   ],
   "source": [
    "# Same steps as above\n",
    "for i in knn_loop:\n",
    "    index = 200\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train_std,y_train)\n",
    "    print('KNN: {}'.format(i))\n",
    "    print('There is a {}% chance that X_test {}  belongs to class 0'.format(knn.predict_proba(X_test_std)[index][0]*100,index))\n",
    "    print('There is a {}% chance that X_test {}  belongs to class 1'.format(knn.predict_proba(X_test_std)[index][1]*100,index))\n",
    "    print('There is a {}% chance that X_test {}  belongs to class 2'.format(knn.predict_proba(X_test_std)[index][2]*100,index))\n",
    "    print()\n",
    "print('True Value: {}'.format(y_test[index]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dbe523",
   "metadata": {},
   "source": [
    "## Build Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3f91c7",
   "metadata": {},
   "source": [
    "### TO DO: scikit-learn Logistic Regression for this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68f7c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and instantiate the Logistic Regression Model in SciKit-Learn is in the cell below\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='newton-cg', multi_class='multinomial',random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e7e1de",
   "metadata": {},
   "source": [
    "### TO DO: Train the model by calling the model's fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75590d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, random_state=0,\n",
       "                   solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, random_state=0,\n",
       "                   solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', random_state=0,\n",
       "                   solver='newton-cg')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit your dataset\n",
    "lr.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee86e3",
   "metadata": {},
   "source": [
    "### TO DO: Evaluate the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b9577a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 1 1 0 2 0 0 2 2 2 0 1 0 2 0 1 2 1 0 2 2 0 0 2 1 1 0 2 2 2 0 2 0 0\n",
      " 0 2 2 0 1 0 1 1 1 2 2 1 0 1 1 0 0 1 0 2 2 0 0 0 2 0 0 2 2 0 2 0 2 0 1 0 0\n",
      " 2 1 0 0 2 1 1 0 1 2 2 0 2 2 1 0 0 0 2 2 0 2 0 2 2 2 0 1 0 2 0 2 2 0 1 2 2\n",
      " 2 0 0 0 0 1 0 2 0 1 1 0 0 2 2 2 1 2 0 0 1 0 1 2 0 2 2 2 1 2 2 0 2 2 2 2 2\n",
      " 0 0 0 2 2 0 2 2 2 2 2 0 2 0 0 2 0 2 0 2 1 0 2 2 2 2 0 2 2 0 2 2 0 2 1 1 1\n",
      " 2 0 0 2 2 2 0 0 0 0 2 2 1 1 0 0 0 0 2 2 1 0 0 0 1 0 2 1 0 1 2 0 0 0 2 2 0\n",
      " 2 2 1 0 2 0 0 1 0 0 2 0 2 0 2 0 2 2 0 2 1 1 0 2 0 1 0 2 1 2 2 0 0 0 1 0 2\n",
      " 2 0 1 0 1 0 1 2 2 2 0 0 0 0 2 0 2 0 1 0 1 1 0 2 0 2 2 1 2 2 1 2 0 2 1 1 2\n",
      " 1 0 1 1 0 1 1 1 2 2 0 0 1 0 0 2 1 2 2 2 2 2 2 0 1 0 1 1 0 2 0 1 2 0 2 2 2\n",
      " 0 1 1 0 2 1 0 2 0 1 0 2 1 2 0 1 2 2 0 1 2 0 2 0 0 0 1 0 0 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# create the model's predictions. Name the prediction vector y_pred\n",
    "y_pred = lr.predict(X_test_std)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e504269",
   "metadata": {},
   "source": [
    "### TO DO: Evaluate the Logistic Regression Model's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c56b722f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Missclassified: 10\n",
      "Accuracy: 0.9726775956284153\n"
     ]
    }
   ],
   "source": [
    "# Use SciKit Learn's built-in scoring method to evaluate the model's performance accuracy\n",
    "print('Num Missclassified: {}'.format((y_pred != y_test).sum()))\n",
    "print('Accuracy: {}'.format(metrics.accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a99c773",
   "metadata": {},
   "source": [
    "## Predicting class-membership probabilities using the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce3abe",
   "metadata": {},
   "source": [
    "### TO DO:class-membership probability index = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cefcec61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 10.90% chance that X_test 10  belongs to class 0\n",
      "There is a 0.02% chance that X_test 10  belongs to class 1\n",
      "There is a 89.08% chance that X_test 10  belongs to class 2\n",
      "\n",
      "True Value: 2\n"
     ]
    }
   ],
   "source": [
    "#Predict the class membership probability by using the a row with index = 10 from the X_test_std data. \n",
    "\n",
    "#Make sure your print statement uses a complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test.\n",
    "index = 10\n",
    "\n",
    "print('There is a {:.2f}% chance that X_test {}  belongs to class 0'.format(lr.predict_proba(X_test_std)[index][0]*100,index))\n",
    "print('There is a {:.2f}% chance that X_test {}  belongs to class 1'.format(lr.predict_proba(X_test_std)[index][1]*100,index))\n",
    "print('There is a {:.2f}% chance that X_test {}  belongs to class 2'.format(lr.predict_proba(X_test_std)[index][2]*100,index))\n",
    "print()\n",
    "print('True Value: {}'.format(y_test[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e54710",
   "metadata": {},
   "source": [
    "### TO DO:class-membership probability index = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4841895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 98.01% chance that X_test 130  belongs to class 0\n",
      "There is a 0.00% chance that X_test 130  belongs to class 1\n",
      "There is a 1.99% chance that X_test 130  belongs to class 2\n",
      "\n",
      "True Value: 0\n"
     ]
    }
   ],
   "source": [
    "# Same steps as above\n",
    "index = 130\n",
    "\n",
    "print('There is a {:.2f}% chance that X_test {}  belongs to class 0'.format(lr.predict_proba(X_test_std)[index][0]*100,index))\n",
    "print('There is a {:.2f}% chance that X_test {}  belongs to class 1'.format(lr.predict_proba(X_test_std)[index][1]*100,index))\n",
    "print('There is a {:.2f}% chance that X_test {}  belongs to class 2'.format(lr.predict_proba(X_test_std)[index][2]*100,index))\n",
    "print()\n",
    "print('True Value: {}'.format(y_test[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba83cc1",
   "metadata": {},
   "source": [
    "### TO DO:class-membership probability index = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "369fe6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 87.00% chance that X_test 200  belongs to class 0\n",
      "There is a 0.00% chance that X_test 200  belongs to class 1\n",
      "There is a 13.00% chance that X_test 200  belongs to class 2\n",
      "\n",
      "True Value: 0\n"
     ]
    }
   ],
   "source": [
    "# Same Steps as above\n",
    "index = 200\n",
    "\n",
    "print('There is a {:.2f}% chance that X_test {}  belongs to class 0'.format(lr.predict_proba(X_test_std)[index][0]*100,index))\n",
    "print('There is a {:.2f}% chance that X_test {}  belongs to class 1'.format(lr.predict_proba(X_test_std)[index][1]*100,index))\n",
    "print('There is a {:.2f}% chance that X_test {}  belongs to class 2'.format(lr.predict_proba(X_test_std)[index][2]*100,index))\n",
    "print()\n",
    "print('True Value: {}'.format(y_test[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896f559",
   "metadata": {},
   "source": [
    "## Build Linear Support Vector Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff64d43",
   "metadata": {},
   "source": [
    "### TO DO:scikit-learn Linear Support Vector Classifier for this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d67b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and instantiate the Linear Support Vector Classifier Model in SciKit-Learn\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Instantiate the Linear SVC model\n",
    "svc = LinearSVC(dual=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ba219",
   "metadata": {},
   "source": [
    "### TO DO: Train the model by calling the model's fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5eba632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(dual=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(dual=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(dual=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit your dataset\n",
    "svc.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff36d946",
   "metadata": {},
   "source": [
    "### TO DO: Evaluate the Linear Suport Vector Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ca21745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 1 1 0 2 0 0 2 2 2 0 1 0 2 0 1 2 1 0 2 2 0 0 2 1 1 0 2 2 2 0 2 0 0\n",
      " 0 2 2 0 1 0 1 1 1 2 2 1 0 1 1 0 0 1 0 2 2 0 0 0 2 0 0 2 2 0 2 0 2 0 1 0 0\n",
      " 2 1 0 0 2 1 1 0 1 2 2 0 2 2 1 0 0 0 2 2 0 2 0 2 2 2 0 1 0 2 0 2 2 0 1 2 2\n",
      " 2 0 0 0 0 1 0 2 0 1 1 0 0 2 2 2 1 2 0 0 1 0 1 2 0 2 2 2 1 2 2 0 2 2 2 2 2\n",
      " 0 0 0 2 2 0 2 2 2 2 2 0 2 0 0 2 0 2 0 2 1 0 2 2 2 2 0 2 2 0 2 2 0 2 1 1 1\n",
      " 2 0 0 2 2 2 0 0 0 0 2 2 1 1 0 0 0 0 2 2 1 0 0 2 1 0 2 1 0 1 2 0 0 0 2 2 0\n",
      " 2 2 1 0 2 0 0 1 0 0 2 0 2 0 2 0 2 2 0 2 1 1 0 2 0 1 0 2 1 2 2 0 0 0 1 0 2\n",
      " 2 0 1 0 1 0 1 2 2 2 0 0 0 0 0 0 2 0 1 0 1 1 0 2 0 2 2 1 2 2 1 2 0 2 1 1 2\n",
      " 1 0 1 1 0 1 1 1 2 2 0 0 1 0 0 2 1 2 2 2 2 2 2 0 1 0 1 1 0 2 0 1 2 0 2 2 2\n",
      " 0 1 1 0 2 1 0 2 0 1 0 2 1 2 0 1 2 2 0 1 0 0 2 0 0 0 1 0 0 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# create the model's predictions. Name the prediction vector y_pred\n",
    "y_pred = svc.predict(X_test_std)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab79820",
   "metadata": {},
   "source": [
    "### TO DO: Evaluate the Linear Suport Vector Model's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5afaa895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9699453551912568\n"
     ]
    }
   ],
   "source": [
    "# Use SciKit Learn's built-in scoring method to evaluate the model's performance accuracy.\n",
    "print('Accuracy: {}'.format(metrics.accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70afe993",
   "metadata": {},
   "source": [
    "### TO DO: Using the Predict Method of the Linear Suport Vector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2cd60c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted score is: [1] \n",
      "The true score is:[1]\n"
     ]
    }
   ],
   "source": [
    "# Use SciKit Learn's built-in predict method to test the model's predictive performance for the first row of data in X_test_std\n",
    "pred = svc.predict(X_test_std[:1])\n",
    "print('The predicted score is: {} \\nThe true score is:{}'.format(pred,y_test[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf88b60",
   "metadata": {},
   "source": [
    "### TO DO:Print the number of misclassifications using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a1d5f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missclassifications: 11\n"
     ]
    }
   ],
   "source": [
    "print('Number of Missclassifications: {}'.format((y_pred != y_test).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b81110",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efee6d9",
   "metadata": {},
   "source": [
    "### TO DO: Compute the Confusion Matrix for the Linear Suport Vector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16da0087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use SciKit Learn's metrics module to compute the model's confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred, labels=svc.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=svc.classes_)\n",
    "disp.plot()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da13c7b8",
   "metadata": {},
   "source": [
    "### TO DO: Classification Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4675c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the output of your confusion matrix, what was the total number of correct classifications of Substance 2?\n",
    "\n",
    "# Enter your answer as markdown in the cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad11997",
   "metadata": {},
   "source": [
    "### 137 instances of class 2 were correctly identified. 4 class 0's were missidentified as class 2's and 7 class 2's were missidentified as class 0's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aab8323",
   "metadata": {},
   "source": [
    "### TO DO: Compute the Classification report for Linear Suport Vector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7516bf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LinearSVC(dual=False) \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       143\n",
      "           1       1.00      1.00      1.00        79\n",
      "           2       0.97      0.95      0.96       144\n",
      "\n",
      "    accuracy                           0.97       366\n",
      "   macro avg       0.97      0.97      0.97       366\n",
      "weighted avg       0.97      0.97      0.97       366\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use SciKit Learn's metrics module to compute the model's classification report.\n",
    "print(\"Classification report for classifier {0} \\n {1:s}\\n\".format(svc,metrics.classification_report(y_test,y_pred,target_names = ['0','1','2'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee08240d",
   "metadata": {},
   "source": [
    "### TO DO: Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c14436",
   "metadata": {},
   "source": [
    "Based on the output of your classification report, out of all the times Substance 1 should have been predicted, what percentage of times was\n",
    "it correctly predicted?\n",
    "\n",
    "Which performance score did you use to evaluate the performance of the model(s) from the confusion matrix /classification report? (HINT: You\n",
    "may need to research the meaning and difference between precision, recall and f1-score)\n",
    "\n",
    "Enter your answer as markdown in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17afff22",
   "metadata": {},
   "source": [
    "### Using the linear support vector, class 1 was correctly predicted 100% of the time. \n",
    "\n",
    "### Since the results were a perfect recall, it doesn't matter which method is used. Precision is 100% because there are no false positives, recall is 100% because there are no false negatives, and the F1 score is a combination of recall and precision, so it is also at 100%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8bca5e",
   "metadata": {},
   "source": [
    "## Serialization\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b07985",
   "metadata": {},
   "source": [
    "### TO DO: Model Persistence - Save/Load the trained classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a777bcf",
   "metadata": {},
   "source": [
    "To receive full credit for this part you must test the saved and re-loaded classifiers on an instance of “unknown” data and show that it correctly\n",
    "classifies the instance. It’s ok if you use an instance (sample) that is from the test set as the “unknown” data.\n",
    "\n",
    "**NOTE: Use either the Logistic Regression Model or the K-Nearest Neighbors Classifier for this part**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d50305",
   "metadata": {},
   "source": [
    "### Step 1: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6099ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign classifer to serialize\n",
    "saved_classifier = LogisticRegression()\n",
    "saved_classifier.fit(X_train_std, y_train)\n",
    "\n",
    "# Pickle (serialize) and save the trained classifier to a folder\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "dest = os.path.join('classifier', 'pkl_objects')\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "    \n",
    "pickle.dump(saved_classifier, open(os.path.join(dest, 'classifier.pkl'),'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a0487",
   "metadata": {},
   "source": [
    "### Step 2: Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef2acf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved the trained classifier into memory\n",
    "os.chdir('classifier')\n",
    "classifier_reloaded = pickle.load(open(os.path.join('pkl_objects','classifier.pkl'),'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c8a14a",
   "metadata": {},
   "source": [
    "### Step 3: Test the re-loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de6d4000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label: [0]\n"
     ]
    }
   ],
   "source": [
    "# Use SciKit Learn's built-in predict method to test the re-loaded model on data from the row of data in X_test_std with index equal to six (6)\n",
    "index = 6\n",
    "predicted_class = classifier_reloaded.predict(X_test_std[index].reshape(1, -1))\n",
    "\n",
    "print(\"Predicted class label:\", predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc0eb2",
   "metadata": {},
   "source": [
    "Give a brief (¼ page) report (in the markdown cell below ) of your analysis detailing your understanding of the analysis, the machine learning\n",
    "models and their comparative performance, statistical insights, etc. (include reference website links if used)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e6794f",
   "metadata": {},
   "source": [
    "### Analyst\n",
    "\n",
    "### Understanding of Analysis\n",
    "\n",
    "### Learning models used & performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9009277",
   "metadata": {},
   "source": [
    "## BONUS (15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22f7ed3",
   "metadata": {},
   "source": [
    "BONUS (15pts): Comparing the Performance of two Supervised Classification Models\n",
    "\n",
    "<p>Model Performance Comparision of two Classifiers\n",
    "Using the logistic regression model and the KNN model (do NOT re-instantiate and re-train the\n",
    "model. Use the last knn model from your previous section), compare the performasnce of the\n",
    "models using the above statistic when we only have one test set. To do this you need to calculate\n",
    "(and print) in individual notebook cells the following:</p>\n",
    "\n",
    "- $E1$ is the error rate for model , your K-Nearest Neighbor Model\n",
    "- $E2$ is the error rate for model , your Logistic Regression Model\n",
    "- q = $\\dfrac{E1-E2}{2}$  , the error rate average \n",
    "- n1 the number of instances in test set A\n",
    "- n2 the number of instances in test set B\n",
    "\n",
    "Using Python, write a simple decision construct to compute and display $P$ , depending on\n",
    "whether $P \\geq 2$. Use a complete sentence in your output.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656f5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
